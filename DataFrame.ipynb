{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f1af09-483e-4d46-a829-e7b46553031b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7282c000-87b8-4d47-98de-d7ed8824cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b721de-28fc-47af-808f-ab90a8b5ffb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f4396f-e03f-44b1-a44b-01059ad13759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/16 08:38:02 WARN Utils: Your hostname, Tulasis-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.9 instead (on interface en0)\n",
      "24/09/16 08:38:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/16 08:38:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.9:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrameP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x105bef5f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName(\"DataFrameP\").master(\"local[4]\")\n",
    "         .config(\"spark.dynamicAllocation.enabled\", \"false\")\n",
    "         .config(\"spark.sql adaptive.enabled\", \"false\")\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4036313-d4cf-45d2-b867-8ed79c0b192c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Create Data frame using RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d44c58-b9b9-41e3-b69e-a74da7cae177",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [1, 'Alice', 25],\n",
    "    [2, 'Bob', 30],\n",
    "    [3, 'Charlie', 22],\n",
    "    [4, 'David', 28],\n",
    "    [5, 'Eve', 27],\n",
    "    [6, 'Frank', 33],\n",
    "    [7, 'Grace', 26],\n",
    "    [8, 'Hannah', 31],\n",
    "    [9, 'Ivy', 29],\n",
    "    [10, 'Jack', 24]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be8e570-252f-42f7-9ec1-0a837713d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRDD = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a261306-7d27-4cd9-b6fd-45a8321292fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| _1|     _2| _3|\n",
      "+---+-------+---+\n",
      "|  1|  Alice| 25|\n",
      "|  2|    Bob| 30|\n",
      "|  3|Charlie| 22|\n",
      "|  4|  David| 28|\n",
      "|  5|    Eve| 27|\n",
      "|  6|  Frank| 33|\n",
      "|  7|  Grace| 26|\n",
      "|  8| Hannah| 31|\n",
      "|  9|    Ivy| 29|\n",
      "| 10|   Jack| 24|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create data frame from RDD\n",
    "dataDF = dataRDD.toDF()\n",
    "dataDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ab64807-1ff3-43c4-aec7-6410bc30cbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---+\n",
      "|S.NO|   Name|Age|\n",
      "+----+-------+---+\n",
      "|   1|  Alice| 25|\n",
      "|   2|    Bob| 30|\n",
      "|   3|Charlie| 22|\n",
      "|   4|  David| 28|\n",
      "|   5|    Eve| 27|\n",
      "|   6|  Frank| 33|\n",
      "|   7|  Grace| 26|\n",
      "|   8| Hannah| 31|\n",
      "|   9|    Ivy| 29|\n",
      "|  10|   Jack| 24|\n",
      "+----+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define cloumn names for Data Frames\n",
    "dataDF = dataDF.toDF(\"S.NO\",\"Name\",\"Age\")\n",
    "dataDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044c46f0-4f72-485d-aebf-a70ac51ce6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- S.NO: long (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print data frame schema\n",
    "\n",
    "dataDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac7480e-75da-4b57-8cc4-be658e1f1106",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Create Data Fame from Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6205da4-f1bb-45af-8c71-b743ba54bb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "|SNO|   Name|Age|\n",
      "+---+-------+---+\n",
      "|  1|  Alice| 25|\n",
      "|  2|    Bob| 30|\n",
      "|  3|Charlie| 22|\n",
      "|  4|  David| 28|\n",
      "|  5|    Eve| 27|\n",
      "|  6|  Frank| 33|\n",
      "|  7|  Grace| 26|\n",
      "|  8| Hannah| 31|\n",
      "|  9|    Ivy| 29|\n",
      "| 10|   Jack| 24|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataDF = spark.createDataFrame(data,[\"S.No\",\"Name\",\"Age\"])\n",
    "dataDF = spark.createDataFrame(data,\"SNO : long, Name: string, Age: long\") # alternative\n",
    "dataDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3579fcbe-961d-4abe-aae0-0ef9264836c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SNO: long (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360dfe6-593d-4361-9191-ff9fd1d12005",
   "metadata": {},
   "source": [
    "# Create Data Frame using a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1df1b534-6dc4-43ac-a04e-a0b2d673c077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='VendorID', _c1='tpep_pickup_datetime', _c2='tpep_dropoff_datetime', _c3='passenger_count', _c4='trip_distance', _c5='RatecodeID', _c6='store_and_fwd_flag', _c7='PULocationID', _c8='DOLocationID', _c9='payment_type', _c10='fare_amount', _c11='extra', _c12='mta_tax', _c13='tip_amount', _c14='tolls_amount', _c15='improvement_surcharge', _c16='total_amount', _c17='congestion_surcharge', _c18='airport_fee'),\n",
       " Row(_c0='1', _c1='2022-10-01T05:33:41.000+05:30', _c2='2022-10-01T05:48:39.000+05:30', _c3='1.0', _c4='1.7', _c5='1.0', _c6='N', _c7='249', _c8='107', _c9='1', _c10='9.5', _c11='3.0', _c12='0.5', _c13='2.65', _c14='0.0', _c15='0.3', _c16='15.95', _c17='2.5', _c18='0.0'),\n",
       " Row(_c0='2', _c1='2022-10-01T05:44:30.000+05:30', _c2='2022-10-01T05:49:48.000+05:30', _c3='2.0', _c4='0.72', _c5='1.0', _c6='N', _c7='151', _c8='238', _c9='2', _c10='5.5', _c11='0.5', _c12='0.5', _c13='0.0', _c14='0.0', _c15='0.3', _c16='9.3', _c17='2.5', _c18='0.0')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file path /Users/tulasiramreddygade/Downloads/apache-spark-3-fundamentals/DataFiles/Raw/YellowTaxis_202210.csv\n",
    "path = \"/Users/tulasiramreddygade/Downloads/apache-spark-3-fundamentals/DataFiles/Raw/YellowTaxis_202210.csv\"\n",
    "yellowTaxisDF = spark.read.csv(path)\n",
    "\n",
    "yellowTaxisDF.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3269fea1-0ef6-44f0-a413-bc55f1a8802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      " |-- airport_fee: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take taxi column from file header row\n",
    "yellowTaxisDF = spark.read.option(\"header\",\"true\").csv(path)\n",
    "\n",
    "yellowTaxisDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee137aa-b072-48a0-91de-bf814211ee51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Read TSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b54e09a0-922b-4acd-9998-f1929674afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "greenTaxiFilePath = \"/Users/tulasiramreddygade/Downloads/apache-spark-3-fundamentals/DataFiles/Raw/GreenTaxis_*.cs\"\n",
    "greenTaxiDF = spark.read.option(\"header\",\"true\").option(\"delimiter\",\"\\t\").csv(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1d5c9-80f6-4c0a-b509-d411ea60ff4a",
   "metadata": {},
   "source": [
    "## Read json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba341d2f-a460-4bc7-a66e-0e5e9f7f6934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|PaymentType|PaymentTypeID|\n",
      "+-----------+-------------+\n",
      "|Credit Card|            1|\n",
      "|       Cash|            2|\n",
      "|  No Charge|            3|\n",
      "|    Dispute|            4|\n",
      "|    Unknown|            5|\n",
      "|Voided Trip|            6|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pathToJsonFile = \"/Users/tulasiramreddygade/Downloads/apache-spark-3-fundamentals/DataFiles/Raw/PaymentTypes.json\"\n",
    "\n",
    "paymentTypeJSON = spark.read.json(pathToJsonFile)\n",
    "\n",
    "# spark.read.format(\"formatType\").Load(path) # Read any type of data \n",
    "paymentTypeJSON.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45319d86-bfb4-4b5c-9e09-038eb6b12f87",
   "metadata": {},
   "source": [
    "# Applying Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8d21352-8598-45c2-9b76-71f3aa107903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: string (nullable = true)\n",
      " |-- trip_distance: string (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- fare_amount: string (nullable = true)\n",
      " |-- extra: string (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: string (nullable = true)\n",
      " |-- tolls_amount: string (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- congestion_surcharge: string (nullable = true)\n",
      " |-- airport_fee: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yellowTaxiDF = spark.read.option(\"header\",\"true\").csv(path)\n",
    "\n",
    "yellowTaxiDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9782a-5e59-4214-92a0-48dac52831ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## InferingSchema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c965ff87-654f-4cc2-b5af-ddaa0233b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "yellowTaxiDFSchemaInference = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(path)\n",
    "\n",
    "yellowTaxiDFSchemaInference.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1cf51f-c0e6-461a-8c7b-ea78cbd8b7b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Define own schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26c8e6ce-d5d1-4285-aa29-5e41fdc37626",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellowTaxiSchema = (StructType([\n",
    "    StructField(\"VendorId\",IntegerType(),True),\n",
    "    StructField(\"tpep_pickup_datetime\",TimestampType(),True),\n",
    "    StructField(\"tpep_dropoff_datetime\",TimestampType(),True),\n",
    "    StructField(\"passenger_count\",DoubleType(),True),\n",
    "    StructField(\"trip_distance\",DoubleType(),True),\n",
    "    StructField(\"RatecodeID\",DoubleType(),True),\n",
    "    StructField(\"store_and_fwd_flag\",StringType(),True),\n",
    "    StructField(\"PULocationID\",IntegerType(),True),\n",
    "    StructField(\"DOLocationID\",IntegerType(),True),\n",
    "    StructField(\"payment_type\",IntegerType(),True),\n",
    "    StructField(\"fare_amount\",DoubleType(),True),\n",
    "    StructField(\"extra\",DoubleType(),True),\n",
    "    StructField(\"mta_tax\",DoubleType(),True),\n",
    "    StructField(\"tip_amount\",DoubleType(),True),\n",
    "    StructField(\"tolls_amount\",DoubleType(),True),\n",
    "    StructField(\"improvement_surcharge\",DoubleType(),True),\n",
    "    StructField(\"total_amount\",DoubleType(),True),\n",
    "    StructField(\"congestion_surcharge\",DoubleType(),True),\n",
    "    StructField(\"airport_fee\",DoubleType(),True)\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a031db9c-7d95-4af3-aeb0-7f56425c6c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorId: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yellowTaxiDFWithSchema = spark.read.option(\"header\",\"true\").schema(yellowTaxiSchema).csv(path)\n",
    "\n",
    "yellowTaxiDFWithSchema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f35e79c-3e10-49c6-a7d2-c33f45067ad4",
   "metadata": {},
   "source": [
    "## Define schema for json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c74694e8-a2c1-4965-9675-8d5dce98f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "TaxiBasesPath = '/Users/tulasiramreddygade/Downloads/apache-spark-3-fundamentals/DataFiles/Raw/TaxiBases.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "367dfad9-aa0b-4644-9cd3-89041a8bd86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Address=Row(Building='636', City='NEW YORK', Postcode=10001, State='NY', Street='WEST   28 STREET'), Date='08/15/2019', Entity Name='VIER-NY,LLC', GeoLocation=Row(Latitude=40.75273, Location='(40.75273, -74.006408)', Longitude=-74.006408), License Number='B02865', SHL Endorsed='No', Telephone Number=6466657536, Time='18:03:31', Type of Base='BLACK CAR BASE')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaxiBasesDF = spark.read.option(\"multiline\",True).json(TaxiBasesPath)\n",
    "\n",
    "TaxiBasesDF.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9d94cbc-9757-4bee-be0d-47c5181f0b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Address: struct (nullable = true)\n",
      " |    |-- Building: string (nullable = true)\n",
      " |    |-- City: string (nullable = true)\n",
      " |    |-- Postcode: long (nullable = true)\n",
      " |    |-- State: string (nullable = true)\n",
      " |    |-- Street: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Entity Name: string (nullable = true)\n",
      " |-- GeoLocation: struct (nullable = true)\n",
      " |    |-- Latitude: double (nullable = true)\n",
      " |    |-- Location: string (nullable = true)\n",
      " |    |-- Longitude: double (nullable = true)\n",
      " |-- License Number: string (nullable = true)\n",
      " |-- SHL Endorsed: string (nullable = true)\n",
      " |-- Telephone Number: long (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Type of Base: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TaxiBasesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "10f3292a-57d7-41d1-ba4a-a427787af1dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+--------------+------------+----------------+--------+--------------------+\n",
      "|             Address|      Date|         Entity Name|         GeoLocation|License Number|SHL Endorsed|Telephone Number|    Time|        Type of Base|\n",
      "+--------------------+----------+--------------------+--------------------+--------------+------------+----------------+--------+--------------------+\n",
      "|{636, NEW YORK, 1...|08/15/2019|         VIER-NY,LLC|{40.75273, (40.75...|        B02865|          No|      6466657536|18:03:31|      BLACK CAR BASE|\n",
      "|{131, BRONX, 1046...|08/15/2019|VETERANS RADIO DI...|{40.86927, (40.86...|        B02634|          No|      7183647878|18:03:31|         LIVERY BASE|\n",
      "|{115-54, ELMONT, ...|08/15/2019|      ALPHA VAN LINE|{40.693473, (40.6...|        B80094|          No|      5162850750|18:03:31|COMMUTER VAN AUTH...|\n",
      "|{866, BROOKLYN, 1...|08/15/2019|A.T.B. CAR AND LI...|{40.667838, (40.6...|        B02677|          No|      7184854444|18:03:31|         LIVERY BASE|\n",
      "|{57-48, MASPETH, ...|08/15/2019|KYOEI LIMOUSINE, ...|{40.722961, (40.7...|        B02152|          No|      7183263258|18:03:31|    LUXURY/LIMOUSINE|\n",
      "|{31-00, LIC, 1110...|08/15/2019|ENDOR CAR & DRIVE...|{40.742082, (40.7...|        B02844|          No|      4154758459|18:03:31|      BLACK CAR BASE|\n",
      "|{68-20A, FRESH ME...|08/15/2019|SKYWAY EXECUTIVE ...|{40.733337, (40.7...|        B02841|          No|      7183595959|18:03:31|      BLACK CAR BASE|\n",
      "|{22-11, LIC, 1110...|08/15/2019|FARRELL'S LEASING...|{40.757077, (40.7...|        B00472|          No|      2128616300|18:03:31|    LUXURY/LIMOUSINE|\n",
      "|{429, BROOKLYN, 1...|08/15/2019|CITY CAR SERVICE ...|{40.668473, (40.6...|        B01739|          No|      7184182222|18:03:31|         LIVERY BASE|\n",
      "|{41-31, FLUSHING,...|08/15/2019|YELLOWSTONE TRANS...|{40.758114, (40.7...|        B00248|          No|      7185397777|18:03:31|         LIVERY BASE|\n",
      "|{1811, BROOKLYN, ...|08/15/2019|ELTRI CAR SERVICE...|{40.612302, (40.6...|        B02861|          No|      7183820100|18:03:31|      BLACK CAR BASE|\n",
      "|{104-08, RICHMOND...|08/15/2019|V.J. CAR & LIMO S...|{40.691906, (40.6...|        B02093|          No|      7186417777|18:03:31|         LIVERY BASE|\n",
      "|{6701, BROOKLYN, ...|08/15/2019|ADVANTAGE LIMO OF...|{40.603784, (40.6...|        B02980|          No|      3478655876|18:03:31|    LUXURY/LIMOUSINE|\n",
      "|{636, NEW YORK, 1...|08/15/2019|          ELF-NY,LLC|{40.75273, (40.75...|        B02878|          No|      6466657540|18:03:31|      BLACK CAR BASE|\n",
      "|{85-02, REGO PARK...|08/15/2019|ALTA MEDICAL TRAN...|{40.717275, (40.7...|        B90691|          No|      7188972582|18:03:31|    PARATRANSIT BASE|\n",
      "|{565, BRONX, 1046...|08/15/2019|   RAELEEN CAR CORP.|{40.755734, (40.7...|        B02840|          No|      9176031815|18:03:31|      BLACK CAR BASE|\n",
      "|{2421, BROOKLYN, ...|08/15/2019|ASCONA CAR SERVIC...|{40.595422, (40.5...|        B02658|          No|      7186461611|18:03:31|         LIVERY BASE|\n",
      "|{6318, BROOKLYN, ...|08/15/2019|CHICO EXPRESS LIM...|{40.625609, (40.6...|        B02331|          No|      7182367777|18:03:31|      BLACK CAR BASE|\n",
      "|{32-10, LIC, 1110...|08/15/2019| LYFE AUTO GROUP INC|{40.734944, (40.7...|        B02969|          No|      7187066234|18:03:31|      BLACK CAR BASE|\n",
      "|{626, UNIONDALE, ...|08/15/2019|SAROS TRANSPORTAT...|{40.638931, (40.6...|        B02651|          No|      7185640084|18:03:31|      BLACK CAR BASE|\n",
      "+--------------------+----------+--------------------+--------------------+--------------+------------+----------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- Address: struct (nullable = true)\n",
      " |    |-- Building: string (nullable = true)\n",
      " |    |-- City: string (nullable = true)\n",
      " |    |-- Postcode: long (nullable = true)\n",
      " |    |-- State: string (nullable = true)\n",
      " |    |-- Street: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Entity Name: string (nullable = true)\n",
      " |-- GeoLocation: struct (nullable = true)\n",
      " |    |-- Latitude: double (nullable = true)\n",
      " |    |-- Location: string (nullable = true)\n",
      " |    |-- Longitude: double (nullable = true)\n",
      " |-- License Number: string (nullable = true)\n",
      " |-- SHL Endorsed: string (nullable = true)\n",
      " |-- Telephone Number: long (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Type of Base: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TaxiBasesDFInferSchema = spark.read.option(\"multiline\",True).option(\"header\",True).option(\"inferSchema\",True).json(TaxiBasesPath)\n",
    "\n",
    "TaxiBasesDFInferSchema.show()\n",
    "TaxiBasesDFInferSchema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "284dedae-ce72-422d-8eed-34913780fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "TaxiBasesDFSchema = StructType([\n",
    "    StructField(\"Address\",StructType([\n",
    "        StructField(\"Building\",StringType(),True),\n",
    "        StructField(\"City\",StringType(),True),\n",
    "        StructField(\"Postcode\",LongType(),True),\n",
    "        StructField(\"State\",StringType(),True),\n",
    "        StructField(\"Street\",StringType(),True)\n",
    "    ]),True),\n",
    "    StructField(\"Date\",StringType(),True),\n",
    "    StructField(\"Entity Name\",StringType(),True),\n",
    "    StructField(\"GeoLocation\",StructType([\n",
    "        StructField(\"Latitude\",DoubleType(),True),\n",
    "        StructField(\"Location\",StringType(),True),\n",
    "        StructField(\"Longitude\",DoubleType(),True)\n",
    "    ])),\n",
    "    StructField(\"License Number\",StringType(),True),\n",
    "    StructField(\"SHL Endorsed\",StringType(),True),\n",
    "    StructField(\"Telephone Number\",LongType(),True),\n",
    "    StructField(\"Time\",StringType(),True),\n",
    "    StructField(\"Type of Base\",StringType(),True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e82db2e2-c18b-4590-a71d-e39403e5b9ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m TaxiBasesDFWithSchema \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mschema(TaxiBasesDFSchema)\u001b[38;5;241m.\u001b[39mjson(TaxiBasesPath)\n\u001b[1;32m      3\u001b[0m TaxiBasesDFWithSchema\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m      4\u001b[0m TaxiBasesDFWithSchema\u001b[38;5;241m.\u001b[39mprintSchema()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyspark/sql/session.py:1706\u001b[0m, in \u001b[0;36mSparkSession.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrameReader:\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;124;03m    Returns a :class:`DataFrameReader` that can be used to read data\u001b[39;00m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;124;03m    in as a :class:`DataFrame`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;124;03m    +---+------------+\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameReader(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pyspark/sql/readwriter.py:70\u001b[0m, in \u001b[0;36mDataFrameReader.__init__\u001b[0;34m(self, spark)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, spark: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparkSession\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39m_jsparkSession\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark \u001b[38;5;241m=\u001b[39m spark\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_new_connection()\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     connection\u001b[38;5;241m.\u001b[39mconnect_to_java_server()\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mconnect((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_port))\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused"
     ]
    }
   ],
   "source": [
    "TaxiBasesDFWithSchema = spark.read.option(\"multiline\",True).schema(TaxiBasesDFSchema).json(TaxiBasesPath)\n",
    "\n",
    "TaxiBasesDFWithSchema.show()\n",
    "TaxiBasesDFWithSchema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9a2ab-a71b-4787-86b5-01debfdf1ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
